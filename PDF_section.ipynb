{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 7, JULY 2016 1455\n",
      "A Dataset for Breast Cancer Histopathological\n",
      "-------------------\n",
      "\n",
      "Image Classiﬁcation\n",
      "\n",
      "-------------------\n",
      "Fabio A. Spanhol∗, Luiz S. Oliveira, Caroline Petitjean, and Laurent Heutte\n",
      "Abstract —Today, medical image analysis papers require solid\n",
      "experiments to prove the usefulness of proposed methods. How-\n",
      "ever, experiments are often performed on data selected by the\n",
      "researchers, which may come from different institutions, scan-\n",
      "ners, and populations. Different evaluation measures may be used,\n",
      "making it difﬁcult to compare the methods. In this paper, we in-\n",
      "troduce a dataset of 7909 breast cancer histopathology images\n",
      "acquired on 82 patients, which is now publicly available from\n",
      "http://web.inf.ufpr.br/vri/breast-cancer-database. The dataset in-\n",
      "cludes both benign and malignant images. The task associated with\n",
      "this dataset is the automated classiﬁcation of these images in two\n",
      "classes, which would be a valuable computer-aided diagnosis tool\n",
      "for the clinician. In order to assess the difﬁculty of this task, we\n",
      "show some preliminary results obtained with state-of-the-art im-\n",
      "age classiﬁcation systems. The accuracy ranges from 80% to 85%,\n",
      "showing room for improvement is left. By providing this dataset\n",
      "and a standardized evaluation protocol to the scientiﬁc community,\n",
      "we hope to gather researchers in both the medical and the machine\n",
      "learning ﬁeld to advance toward this clinical application.\n",
      "Index Terms —Breast cancer, histopathology, image classiﬁca-\n",
      "tion, medical imaging.\n",
      "-------------------\n",
      "\n",
      "I. INTRODUCTION\n",
      "\n",
      "-------------------\n",
      "CANCER is a signiﬁcant public health problem in the world\n",
      "today. According to the International Agency for Research\n",
      "on Cancer of the World Health Organization, 8.2 million deaths\n",
      "were caused by cancer in 2012 and 27 million of new cases of\n",
      "this disease are expected before 2030 [1]. In particular, breast\n",
      "cancer (BC) is one of most common types of cancer among\n",
      "women. Mortality of BC is very high when compared to other\n",
      "types of cancer.\n",
      "Detection and diagnosis of BC can be achieved by imaging\n",
      "procedures such as diagnostic mammograms (X-rays), magnetic\n",
      "resonance imaging, ultrasound (sonography), and thermogra-\n",
      "phy [2]. Imaging for cancer screening has been investigated for\n",
      "more than four decades [3]. However, biopsy is the only way\n",
      "to diagnose with conﬁdence if cancer is really present. Among\n",
      "biopsy techniques, the most common are ﬁne needle aspiration,\n",
      "core needle biopsy, vacuum-assisted, and surgical (open) biopsy\n",
      "Manuscript received May 14, 2015; revised August 18, 2015 and October\n",
      "21, 2015; accepted October 22, 2015. Date of publication October 30, 2015;\n",
      "date of current version June 16, 2016. This work was supported by the National\n",
      "Council for Scientiﬁc and Technological Development (CNPq), Brazil, under\n",
      "grant #301653/2011-9 and the Coordination for the Improvement of Higher\n",
      "Level Personnel (CAPES) through SticAmsud project #263/2014. Asterisk\n",
      "indicates corresponding author.\n",
      "∗F. A. Spanhol is with the Federal University of Parana, Curitiba-PR 80060-\n",
      "000, Brazil (e-mail: faspanhol@inf.ufpr.br).\n",
      "L. S. Oliveira is with the Federal University of Parana.\n",
      "C. Petitjean and L. Heutte are with LITIS EA 4108, Universit ´e de Rouen.\n",
      "Color versions of one or more of the ﬁgures in this paper are available online\n",
      "at http://ieeexplore.ieee.org.\n",
      "Digital Object Identiﬁer 10.1109/TBME.2015.2496264(SOB) [4]. The procedure consists in collecting samples of cells\n",
      "or tissue, which are ﬁxed across a glass microscope slide for\n",
      "subsequent staining and microscopic examination. Diagnosis\n",
      "from a histopathology image is thus the gold standard in diag-\n",
      "nosing almost all types of cancer, including BC [5], [6]. The\n",
      "ﬁnal BC diagnosis, including grading and staging, is done by\n",
      "pathologists applying visual inspection of histological samples\n",
      "under microscope.\n",
      "Histopathological analysis is a highly time-consuming spe-\n",
      "cialized task, dependent on the experience of the pathologists\n",
      "and inﬂuenced by factors such as fatigue and decrease of atten-\n",
      "tion. As pointed by Gurcan et al. [7], there is a pressing need\n",
      "for computer-assisted diagnosis (CAD) to relieve the workload\n",
      "on pathologists by ﬁltering obviously benign areas, so that the\n",
      "experts can focus on the more difﬁcult-to-diagnose cases [8].\n",
      "A considerable amount of efforts has thus been devoted to\n",
      "the ﬁeld of BC histopathology image analysis, and in particular\n",
      "to the automated classiﬁcation of benign or malignant images,\n",
      "for computer-aided diagnosis. Kowal et al. [9] compare and test\n",
      "different algorithms for nuclei segmentation on a dataset of 500\n",
      "images, for which accuracies ranging from 96% to 100% are re-\n",
      "ported. Filipczuk et al. [10] present a BC diagnosis system based\n",
      "on the analysis of cytological images of ﬁne needle biopsies, to\n",
      "discriminate the images as either benign or malignant. Using\n",
      "four different classiﬁers trained with a 25-D feature vector, they\n",
      "report a performance of 98% on 737 images. Similarly to [9]\n",
      "and [10], George et al. [11] propose a diagnosis system for BC\n",
      "based on the nuclei segmentation of cytological images. Using\n",
      "different machine learning models, such as neural networks and\n",
      "support vector machines (SVMs), they report accuracy rates\n",
      "ranging from 76% to 94% on a dataset of 92 images. Zhang\n",
      "et al. [12] propose a cascade approach with rejection option. In\n",
      "the ﬁrst level of the cascade, authors expect to solve the easy\n",
      "cases, while the hard ones are sent to a second level where a\n",
      "more complex pattern classiﬁcation system is used. They assess\n",
      "the proposed method on a database proposed by the Israel In-\n",
      "stitute of Technology, which is composed of 361 images (40 ×\n",
      "magniﬁcation). On this dataset, they report results of 97% of\n",
      "reliability. In another work [13], the same authors assessed an\n",
      "ensemble of one-class classiﬁers on the same database achieving\n",
      "a recognition rate of 92%.\n",
      "We can gather from the literature that most of the works on BC\n",
      "histopathology image analysis are carried out on small datasets,\n",
      "which are usually not available to the scientiﬁc community. In a\n",
      "recent review, Veta et al. [14] point out that the main obstacle in\n",
      "the development of new histopathology image analysis methods\n",
      "is the lack of large, publicly available, annotated datasets. An-\n",
      "notated database is also crucial to develop and validate machine\n",
      "learning systems.\n",
      "0018-9294 © 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.\n",
      "See http://www.ieee.org/publications standards/publications/rights/index.html for more information. Authorized licensed use limited to: DA IICT. Downloaded on December 13,2023 at 18:55:37 UTC from IEEE Xplore.  Restrictions apply. 1456 IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 7, JULY 2016\n",
      "In this paper, we introduce a database, called BreaKHis, that\n",
      "is intended to mitigate this gap. BreaKHis is composed of 7909\n",
      "clinically representative microscopic images of breast tumor\n",
      "tissue images collected from 82 patients using different magni-\n",
      "fying factors (40 ×, 100×, 200×, and 400 ×). To date, it con-\n",
      "tains 2480 benign and 5429 malignant samples. This database\n",
      "has been built in collaboration with the P&D Laboratory1—\n",
      "Pathological Anatomy and Cytopathology, Parana, Brazil. We\n",
      "believe that researchers will ﬁnd this database useful as it makes\n",
      "future benchmarking and evaluation possible. The database is\n",
      "available for research purposes from now on, upon request.2\n",
      "Additionally, we present in this paper the classiﬁcation\n",
      "performance of a baseline pattern recognition system, designed\n",
      "to discriminate between benign and malignant tumors with\n",
      "state-of-the-art feature extractors and classiﬁers, with the aim\n",
      "of showing the difﬁculty of the problem. The classiﬁcation\n",
      "system is based on four machine learning models, trained with\n",
      "different textural representations and keypoint detectors. A\n",
      "comprehensive set of experiments shows that accuracy rates\n",
      "with this baseline system range from 80% to 85%, depending\n",
      "on the image magniﬁcation factor. To give an insight about the\n",
      "discriminative power of the textural representations we have\n",
      "used, we also present the performance of the oracle. The oracle\n",
      "is an abstract model deﬁned in [15], which always selects the\n",
      "classiﬁer that predicted the correct label, for a given query\n",
      "sample, if such a classiﬁer exists. In other words, it represents\n",
      "the ideal classiﬁer selection scheme. The difference between\n",
      "the performance of a real-life classiﬁcation system and the\n",
      "abstract model of the oracle shows that room for improvement\n",
      "is left with a high potential of increased accuracy. Performance\n",
      "may be improved by using dedicated, improved descriptors, or\n",
      "designing a strategy to select appropriate descriptors.\n",
      "This paper is structured as follows. Section II introduces the\n",
      "proposed database. Section III describes the feature sets and the\n",
      "classiﬁers. Section IV reports our experiments and discusses our\n",
      "results. Finally, Section V concludes the work.\n",
      "-------------------\n",
      "\n",
      "II. B REAKHISDATASET\n",
      "\n",
      "-------------------\n",
      "The BreaKHis database contains microscopic biopsy images\n",
      "of benign and malignant breast tumors. Images were collected\n",
      "through a clinical study from January 2014 to December 2014.\n",
      "All patients referred to the P&D Laboratory, Brazil, during this\n",
      "period of time, with a clinical indication of BC were invited to\n",
      "participate in the study. The institutional review board approved\n",
      "the study and all patients gave written informed consent. All the\n",
      "data were anonymized.\n",
      "Samples are generated from breast tissue biopsy slides,\n",
      "stained with hematoxylin and eosin (HE). The samples are col-\n",
      "lected by SOB, prepared for histological study, and labeled by\n",
      "pathologists of the P&D Lab. The preparation procedure used in\n",
      "this work is the standard parafﬁn process, which is widely used\n",
      "in clinical routine. The main goal is to preserve the original tissue\n",
      "structure and molecular composition, allowing to observe it in a\n",
      "1http://www.prevencaoediagnose.com.br/\n",
      "2http://web.inf.ufpr.br/vri/breast-cancer-databaseTABLE I\n",
      "-------------------\n",
      "\n",
      "MAGNIFICATION AND DIGITAL RESOLUTION OF THE ACQUISITION SYSTEM\n",
      "Visual Objective Effective\n",
      "\n",
      "-------------------\n",
      "magniﬁcation lens pixel size ( μm)\n",
      "40× 4× 0.49\n",
      "100× 10× 0.20\n",
      "200× 20× 0.10\n",
      "400× 40× 0.05\n",
      "light microscope. The complete preparation procedure includes\n",
      "steps such as ﬁxation, dehydration, clearing, inﬁltration, em-\n",
      "bedding, and trimming [16]. To be mounted on slides, sections\n",
      "of 3μm are cut using a microtome. After staining, the sections\n",
      "are covered with a glass coverslip. Then, the anatomopatholo-\n",
      "gists identify the tumoral areas in each slide, by visual analysis\n",
      "of tissue sections under a microscope. Final diagnosis of each\n",
      "case is produced by experienced pathologists and conﬁrmed by\n",
      "complementary exams such as immunohistochemistry analysis.\n",
      "An Olympus BX-50 system microscope with a relay lens\n",
      "with magniﬁcation of 3.3 ×coupled to a Samsung digital color\n",
      "camera SCC-131AN is used to obtain digitized images from the\n",
      "breast tissue slides. This camera uses a 1/3” Sony Super-HAD\n",
      "(Hole-Accumulation Diode) interline transfer charge-coupled\n",
      "device with pixel size 6.5 μm×6.25μm and a total pixel\n",
      "number of 752 ×582. Images are acquired in three-channel\n",
      "red–green–blue (RGB) TrueColor (24-bit color depth, 8 bits per\n",
      "color channel) color space using magnifying factors of 40×,\n",
      "100×,200×, and400×, corresponding to objective lens 4×,\n",
      "10×,20×, and40×. The camera is set for automatic exposure\n",
      "and focusing is done manually on the microscope looking at\n",
      "the digital image on the computer screen. Table I shows the\n",
      "effective pixel size in micrometers for each magnifying factor\n",
      "and objective lens we have used. The pixel size is the physical\n",
      "pixel size of the camera (6.5 μm), divided by the relay lens\n",
      "magniﬁcation (3.3) and the objective lens.\n",
      "The original images contain black borders on both the left\n",
      "and right sides and text annotations in the upper left corner. To\n",
      "remove these undesired areas, the resulting images are cropped\n",
      "and saved in three-channel RGB, 8-bit depth in each channel,\n",
      "portable network graphics format with no compression, dimen-\n",
      "sion of 700×460pixels. Resulting images are raw images with-\n",
      "out normalization nor color standardization.\n",
      "The acquisition of images at different magniﬁcations is per-\n",
      "formed as follows: ﬁrst the pathologist identiﬁes the tumor and\n",
      "deﬁnes a region of interest (ROI). To cover the whole ROI, sev-\n",
      "eral images are captured using the lowest magniﬁcation, i.e.,\n",
      "40×. The pathologist preferentially selects images with a single\n",
      "type of tumor (majority of the cases), but some of the images\n",
      "also include transitional tissue, e.g., normal-pathological. In av-\n",
      "erage, a total of 24 images per patient is captured from each slide\n",
      "using the lowest magniﬁcation (see Table II). Then, the mag-\n",
      "niﬁcation is manually increased to 100 ×and a similar number\n",
      "of images is captured inside the initial ROI. This process is re-\n",
      "peated for 200 ×and 400 ×magniﬁcations, respectively. A ﬁnal\n",
      "visual (i.e., manual) inspection discards out-of-focus images.\n",
      "Authorized licensed use limited to: DA IICT. Downloaded on December 13,2023 at 18:55:37 UTC from IEEE Xplore.  Restrictions apply. SPANHOL et al. : A DATASET FOR BREAST CANCER HISTOPATHOLOGICAL IMAGE CLASSIFICATION 1457\n",
      "TABLE II\n",
      "-------------------\n",
      "\n",
      "IMAGE DISTRIBUTION BY MAGNIFICATION FACTOR AND CLASS\n",
      "Magniﬁcation Benign Malignant Total\n",
      "\n",
      "-------------------\n",
      "40× 625 1370 1995\n",
      "100× 644 1437 2081\n",
      "200× 623 1390 2013\n",
      "400× 588 1232 1820\n",
      "Total 2480 5429 7909\n",
      "# Patients 24 58 82\n",
      "TABLE III\n",
      "-------------------\n",
      "\n",
      "BENIGN IMAGE DISTRIBUTION BY MAGNIFICATION FACTOR\n",
      "AND HISTOLOGICAL SUBTYPES\n",
      "Magniﬁcation A F TA PT Total\n",
      "\n",
      "-------------------\n",
      "40× 114 253 109 149 598\n",
      "100× 113 260 121 150 614\n",
      "200× 111 264 108 140 594\n",
      "400× 106 237 115 130 562\n",
      "Total 444 1014 453 569 2368\n",
      "# Patients 4 10 3 7 24\n",
      "TABLE IV\n",
      "-------------------\n",
      "\n",
      "MALIGNANT IMAGE DISTRIBUTION BY MAGNIFICATION FACTOR AND\n",
      "HISTOLOGICAL SUBTYPES\n",
      "Magniﬁcation DC LC MC PC Total\n",
      "\n",
      "-------------------\n",
      "40× 864 156 205 145 1370\n",
      "100× 903 170 222 142 1437\n",
      "200× 896 163 196 135 1390\n",
      "400× 788 137 169 138 1232\n",
      "Total 3451 626 792 560 5429\n",
      "# Patients 38 5 9 6 58\n",
      "To date, the database is composed of 7909 images divided\n",
      "into benign and malignant tumors. Table II summarizes the im-\n",
      "age distribution. Both breast tumors, benign and malignant, can\n",
      "be sorted into different types based on the aspect of the tumoral\n",
      "cells under the microscope. The dataset currently contains four\n",
      "histological distinct types of benign breast tumors: adenosis\n",
      "(A), ﬁbroadenoma (F), phyllodes tumor (PT), and tubular ade-\n",
      "noma (TA); and four malignant tumors (breast cancer): ductal\n",
      "carcinoma (DC), lobular carcinoma (LC), mucinous carcinoma\n",
      "(MC), and papillary carcinoma (PC). The distribution of benign\n",
      "and malignant tumors in these classes is presented in Tables III\n",
      "and IV, respectively.\n",
      "Fig. 1 shows four images—with the four magniﬁcation factors\n",
      "(a)40×,( b )100×,( c )200×, and (d) 400×—acquired from a\n",
      "single slide of breast tissue containing a malignant tumor (breast\n",
      "cancer). Highlighted rectangle (manually added for illustrative\n",
      "purposes only) is the area of interest selected by pathologist to\n",
      "be detailed in the next higher magniﬁcation.\n",
      "-------------------\n",
      "\n",
      "III. F EATURE EXTRACTORS AND CLASSIFIERS\n",
      "\n",
      "-------------------\n",
      "Histological tissue images can be characterized by two types\n",
      "of approaches. The ﬁrst one is based on explicit segmentation\n",
      "Fig. 1. Slide of breast malignant tumor (stained with HE) seen in different\n",
      "magniﬁcation factors: (a) 40×,( b )100×,( c )200×,a n d( d ) 400×. Highlighted\n",
      "rectangle (manually added for illustrative purposes only) is the area of interest\n",
      "selected by pathologist to be detailed in the next higher magniﬁcation factor.\n",
      "to extract structure properties, such as nuclei shape, glandular\n",
      "unit shape, etc., while the second one is a global approach based\n",
      "on texture representation. Since segmentation of histological\n",
      "tissue images is not a trivial task and can be prone to errors, we\n",
      "have chosen a global approach based on state-of-the-art texture\n",
      "representation.\n",
      "In this section, we brieﬂy describe all the representations\n",
      "we have used to train the classiﬁers. These include the textural\n",
      "descriptors most commonly found in the literature, such as local\n",
      "binary patterns (LBP) [17], completed LBP (CLBP) [18], local\n",
      "phase quantization (LPQ) [19], gray-level co-occurrence matrix\n",
      "(GLCM) [20], threshold adjacency statistics (TAS) [21], and one\n",
      "keypoint descriptor, named ORB [22]. Keypoint descriptors are\n",
      "most often used for object recognition; however, the literature\n",
      "shows that this kind of descriptor can produce interesting results\n",
      "for texture classiﬁcation on microscopic images [23].\n",
      "-------------------\n",
      "\n",
      "A. Local Binary Patterns\n",
      "\n",
      "-------------------\n",
      "The LBP operator [17] consists in computing the distribution\n",
      "of binary patterns in the circular neighborhood of each pixel.\n",
      "The neighborhood is characterized by a radius Rand a number\n",
      "of neighbors P. The principle is to threshold neighboring pixels,\n",
      "compared to the central pixel: to each of the Pneighbors, the\n",
      "value 1 is assigned, if the current pixel intensity is superior\n",
      "or equal to the central pixel intensity; otherwise, value 0 is\n",
      "assigned. Thus, for each pixel, a binary pattern is obtained from\n",
      "the neighborhood. A total of 2Pdifferent binary patterns can be\n",
      "obtained. The LBP code at pixel pis obtained by computing the\n",
      "scalar product between the binary code and a vector of powers\n",
      "of two, and summing up the result:\n",
      "LBP(p)=P−1/summationdisplay\n",
      "i=02i.δ(f(qi)−f(p)) (1)\n",
      "where f(qi)andf(p)are gray levels of pixels qiandp, respec-\n",
      "tively, and δis the Kronecker function. Histogram of the LBP\n",
      "Authorized licensed use limited to: DA IICT. Downloaded on December 13,2023 at 18:55:37 UTC from IEEE Xplore.  Restrictions apply. 1458 IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 7, JULY 2016\n",
      "codes can then be used as a texture descriptor. Note that some\n",
      "patterns, which are identical up to one or several rotations, do not\n",
      "have the same LBP code: for example, 10000000 and 01000000\n",
      "have 255 and 128 as LBP codes, respectively. This behavior can\n",
      "be avoided with the rotation invariant LBP, introduced in [17]:\n",
      "each pattern is rotated Ptimes, and the minimum LBP code over\n",
      "theProtations is retained. With this modiﬁcation, 1000000 and\n",
      "01000000 have the same LBP code. For P=8, the rotation in-\n",
      "variant LBP method decreases the number of possible patterns\n",
      "from 256 to 36.\n",
      "Another improvement originated from the observation that\n",
      "some binary patterns occur more often in texture images than\n",
      "others. These frequent patterns are usually those with a small\n",
      "number of transitions, i.e., 0-1 or 1-0: for example, 00000000\n",
      "(no transition), 011111111 (two transitions), 00011111 (two\n",
      "transitions) occur more often than 10101010 (eight transitions),\n",
      "or 01100101 (six transitions). The frequent patterns are called\n",
      "uniform patterns [17]. The LBP method that takes into account\n",
      "uniform patterns makes the number of LBP codes used for\n",
      "histogram bins decrease from 36 to 10. In our experiments, we\n",
      "work with rotation-invariant uniform patterns, with a standard\n",
      "value of P=8neighbors, providing a 10-D feature vector.\n",
      "-------------------\n",
      "\n",
      "B. Completed Local Binary Pattern\n",
      "\n",
      "-------------------\n",
      "The CLBP is one of the latest variants of LBP is the CLBP\n",
      "[18], which provides a completed modeling of the LBP, based on\n",
      "three components extracted from the local region: center pixel,\n",
      "sign, and magnitude. The center pixel is coded by a binary code\n",
      "after global thresholding, with the threshold set as the average\n",
      "gray level of the whole image. For the two other components, a\n",
      "neighborhood of radius Rand number of neighbors Pis consid-\n",
      "ered, similarly to LBP. The difference signs and magnitudes are\n",
      "then computed and coded by speciﬁc operator into binary format\n",
      "so that they can be combined to form the ﬁnal CLBP histogram\n",
      "[18]. Note that the operator coding the sign component corre-\n",
      "sponds to the original LBP operator. We have assessed different\n",
      "conﬁgurations suggested in [18] and the best results observed in\n",
      "our experiments have been obtained with the combination of all\n",
      "components using a 3-D joint histogram, while the best values\n",
      "for the parameters PandRare 24 and 5, respectively, yielding\n",
      "a 1352-D feature vector.\n",
      "-------------------\n",
      "\n",
      "C. Local Phase Quantization\n",
      "\n",
      "-------------------\n",
      "LPQ is based on quantized phase information of the discrete\n",
      "Fourier transform (DFT) [19]. It uses the local phase informa-\n",
      "tion extracted using the 2-D DFT or, more precisely, a short-\n",
      "term Fourier transform computed over a rectangular M×M\n",
      "neighborhood Npat each pixel position pof the image f(p).\n",
      "The quantized coefﬁcients are represented as integer values in\n",
      "the range 0–255 using binary coding described in [19]. These\n",
      "binary codes are generated and accumulated in a 256-bin his-\n",
      "togram, similar to the LBP method. The accumulated values in\n",
      "the histogram are used as the LPQ 256-D feature vector. In our\n",
      "experiments, a variant of LPQ, named LPQ-TOP [24], produced\n",
      "better results. The main difference is that LPQ and LPQ-TOP\n",
      "use different default values for their parameters.\n",
      "Fig. 2. PFTAS thresholding on a malignant image. From left to right, top\n",
      "to bottom: original image, binarized images using threshold ranges [ μ+σ,\n",
      "μ−σ], [μ−σ, 255], and [ μ, 255].\n",
      "D. Gray-Level Co-Occurrence Matrices\n",
      "GLCM are widely used to characterize texture images. In\n",
      "our experiments, four adjacency directions 0◦,45◦,90◦,135◦,\n",
      "and eight gray levels are used to compute the GLCM. On the\n",
      "GLCM, 13 Haralick parameters are computed [20]: angular\n",
      "second moment, contrast, correlation, sum of squares, variance,\n",
      "inverse difference moment, sum average, sum variance, sum\n",
      "entropy, entropy, difference variance, difference entropy, infor-\n",
      "mation measures of correlation 1, and information measures of\n",
      "correlation 2. Finally, we obtain a ﬁnal feature vector by aver-\n",
      "aging the 13-D feature vectors in the four directions.\n",
      "E. Parameter-Free Threshold Adjacency Statistics (PFTAS)\n",
      "The TAS is a simple and fast morphological measure intro-\n",
      "duced in [21] for cell phenotype image classiﬁcation. Since\n",
      "BC images share some similarities with these images, we have\n",
      "used the PFTAS [25], the parameter-free version of TAS. Its\n",
      "principle is to accumulate in the histogram bins, pixels accord-\n",
      "ing to their number of white neighbors, in multiple-threshold\n",
      "binarized images. The original image is binarized using three\n",
      "different threshold ranges: [ μ+σ,μ−σ], [μ−σ, 255], and [ μ,\n",
      "255], where μis an Otsu deﬁned threshold, and σis the standard\n",
      "deviation of the above threshold pixels. Fig. 2 illustrates these\n",
      "images.\n",
      "For each binarized image, a normalized histogram of pixels\n",
      "having i(iranging from 0 to 8) white pixels as neighbors is\n",
      "computed. All three histograms are concatenated to form a 27-\n",
      "D feature vector for each one of three RGB channels, yielding a\n",
      "81-D feature vector. Finally, this vector and its bitwise negated\n",
      "version are concatenated, resulting in a 162-D feature vector.\n",
      "-------------------\n",
      "\n",
      "F. O R B\n",
      "\n",
      "-------------------\n",
      "ORB (for Oriented FAST and Rotated BRIEF) [22] has been\n",
      "proposed as an alternative to the traditional SIFT [26] and SURF\n",
      "[27] keypoint detectors, in terms of computational cost and\n",
      "matching performance. It is designed to be rotation invariant\n",
      "and resistant to noise. ORB is based on the well-known FAST\n",
      "Authorized licensed use limited to: DA IICT. Downloaded on December 13,2023 at 18:55:37 UTC from IEEE Xplore.  Restrictions apply. SPANHOL et al. : A DATASET FOR BREAST CANCER HISTOPATHOLOGICAL IMAGE CLASSIFICATION 1459\n",
      "keypoint detector [28] and the BRIEF keypoint descriptor [29].\n",
      "ORB works as follows: ﬁrst FAST is used to ﬁnd keypoints; then,\n",
      "Harris corner detection selects the top Npoints among them.\n",
      "Since FAST features do not have an orientation component,\n",
      "an efﬁciently computed orientation is added. This orientation\n",
      "compensation mechanism makes ORB rotation invariant.\n",
      "In this work, we have used the OpenCV implementation [30]\n",
      "with the default parameters, which returns a 32-D vector for\n",
      "each keypoint. Best results have been achieved using 500 key-\n",
      "points, considering balance between runtime and improvement\n",
      "of recognition rate. At the end, the image is represented by a\n",
      "single 32-D vector that contains the average of all keypoints.\n",
      "-------------------\n",
      "\n",
      "G. Classiﬁers\n",
      "\n",
      "-------------------\n",
      "Four different classiﬁers were used to assess the aforemen-\n",
      "tioned feature sets: a 1-nearest neighbor (1-NN), quadratic lin-\n",
      "ear analysis (QDA), SVMs, and random forests (RF) of decision\n",
      "trees. A k-NN is a type of instance-based learning that stores all\n",
      "available training data and classiﬁes the testing samples based\n",
      "on a similarity measure (e.g., Euclidean distance). In particular,\n",
      "the 1-NN is often used to assess the discriminating power of\n",
      "the features. QDA is closely related to linear discriminant anal-\n",
      "ysis (LDA), where it is assumed that the measurements from\n",
      "each class are normally distributed. Unlike LDA however, QDA\n",
      "does not assume that the covariance of each of the classes is\n",
      "identical. SVM, a very popular classiﬁcation algorithm, builds\n",
      "a hyperplane in a high-dimensional space, which can be used\n",
      "for classiﬁcation and regression. Differently from other linear\n",
      "discriminant functions, it provides the optimal hyperplane that\n",
      "separates two classes [31]. RF is an ensemble approach that\n",
      "combines decision tree predictors. The principle behind ensem-\n",
      "ble methods is that a group of weak learners (in this case the\n",
      "decision trees) can come together to form a strong learner [32].\n",
      "One of the advantages of the RF is that they are quite fast and\n",
      "able to deal with unbalanced data.\n",
      "IV . E XPERIMENTS AND DISCUSSION\n",
      "-------------------\n",
      "\n",
      "A. Protocol\n",
      "\n",
      "-------------------\n",
      "The BreaKHis dataset has been randomly divided into a train-\n",
      "ing (70%) and a testing (30%) set. To make sure the classiﬁer\n",
      "generalizes to unseen patients, we guarantee that patients used to\n",
      "build the training set are not used for the testing set. The results\n",
      "presented in this work are the average of ﬁve trials. This proto-\n",
      "col was applied independently to each of the four magniﬁcations\n",
      "available. Note that we have also made the folds available along\n",
      "with the dataset, to allow for a full comparison of classiﬁcation\n",
      "results.\n",
      "For the SVM, different kernels were tried; we retained the\n",
      "Gaussian kernel which produced the best results. The kernel\n",
      "parameters γandCwere empirically deﬁned through a grid\n",
      "search and ﬁvefold cross-validation using the training set. The\n",
      "same protocol was applied to tune the parameters of the RF. All\n",
      "the experiments were carried out using scikit-learn, an open-\n",
      "source machine learning library in Python [33]. Table V recalls\n",
      "the six representations we have used to train the classiﬁers.TABLE V\n",
      "-------------------\n",
      "\n",
      "SUMMARY OF THE DESCRIPTORS\n",
      "\n",
      "-------------------\n",
      "Name Feature number\n",
      "CLBP 1352\n",
      "GLCM 13\n",
      "LBP 10\n",
      "LPQ 256\n",
      "ORB 32\n",
      "PFTAS 162\n",
      "Since the decision is patientwise, we report the recognition\n",
      "rate at the patient level, and not at the image level. Let NPbe\n",
      "the cancer images of patient P. For each patient, if Nrecimages\n",
      "are correctly classiﬁed, then one can deﬁne a patient score as\n",
      "Patient Score =Nrec\n",
      "NP(2)\n",
      "and the global recognition rate as\n",
      "Recognition Rate =/summationtextPatient score\n",
      "Total number of patients. (3)\n",
      "The receiver operating characteristic (ROC) curve is another\n",
      "valuable tool for performance analysis, especially since our data\n",
      "are unbalanced data. Indeed, the ROC curve is insensitive to\n",
      "changes in class distribution. If the proportion of positive to\n",
      "negative instances changes in a test set, the ROC curves will not\n",
      "change [34].\n",
      "-------------------\n",
      "\n",
      "B. Results\n",
      "\n",
      "-------------------\n",
      "Table VI reports the performance of all classiﬁers and de-\n",
      "scriptors we have assessed. We propose a two-level analysis of\n",
      "this table. Let us ﬁrst focus on the inﬂuence of the magniﬁcation\n",
      "factors, by comparing columns (best results in bold). Interest-\n",
      "ingly, the magniﬁcation factors do not seem to have the same\n",
      "level of information. In particular, the ﬁrst level (40 ×) exhibits\n",
      "the best results over CLBP, LBP, and ORB. This slight tendency\n",
      "that 40 ×may be the most informative magniﬁcation factor is in\n",
      "accordance with the pathologist behavior, which starts by exam-\n",
      "ining factor 40 and switches to the next level, until he establishes\n",
      "his diagnosis. Note, however, that the 200 ×magniﬁcation fac-\n",
      "tor also shows high potential, with the best results over GLCM\n",
      "and PFTAS, higher than those obtained with the 40 ×level. The\n",
      "complementarity of the magniﬁcation factors could be fruitfully\n",
      "investigated in the future, through a coarse-to-ﬁne analysis for\n",
      "example. It is beyond the scope of this paper.\n",
      "The other level of analysis concerns the feature vector com-\n",
      "parison (best results are underlined in Table VI). All feature\n",
      "vectors exhibit stable and close results. These results are lit-\n",
      "tle inﬂuenced by the classiﬁers: for each factor and for each\n",
      "feature vector, the recognition rates of the four classiﬁers are\n",
      "in a range of less than 4%. Note, however, that the results ob-\n",
      "tained by CLBP with QDA fall out of this range and are far\n",
      "below the other mean recognition rates. Indeed, QDA is based\n",
      "on the estimation of covariance matrices: in order to make a\n",
      "proper estimation of these matrices, a large amount of samples is\n",
      "Authorized licensed use limited to: DA IICT. Downloaded on December 13,2023 at 18:55:37 UTC from IEEE Xplore.  Restrictions apply. 1460 IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 7, JULY 2016\n",
      "TABLE VI\n",
      "-------------------\n",
      "\n",
      "MEAN RECOGNITION RATES AND STANDARD DEVIATIONS OF THE CLASSIFIERS\n",
      "TRAINED WITHDIFFERENT DESCRIPTORS\n",
      "Descriptor Classiﬁer Magniﬁcation Factors\n",
      "\n",
      "-------------------\n",
      "40× 100× 200× 400×\n",
      "CLBP 1-NN 73.6±2.5 71.0 ±2.8 69.4 ±1.5 70.1 ±1.3\n",
      "QDA 39.4 ±13.5 51.7±17.3 50.3 ±16.0 49.4 ±15.5\n",
      "RF 74.5±0.7 72.5 ±3.8 70.0 ±2.4 72.3 ±2.1\n",
      "SVM 77.4±3.8 76.4±4.5 70.2 ±3.6 72.8 ±4.9\n",
      "GLCM 1-NN 74.7 ±1.0 76.8 ±2.1 83.4±3.3 81.7±3.3\n",
      "QDA 67.0 ±6.0 74.2 ±3.5 78.6±1.7 77.0 ±2.3\n",
      "RF 73.6 ±1.5 76.0 ±1.9 82.4±2.3 79.8±2.5\n",
      "SVM 74.0 ±1.3 78.6 ±2.6 81.9±4.9 81.1 ±3.2\n",
      "LBP 1-NN 75.6±2.4 73.0 ±2.4 72.9 ±2.3 71.2 ±3.6\n",
      "QDA 69.7 ±3.8 69.7 ±4.2 68.8 ±4.7 72.3±4.6\n",
      "RF 74.0±2.9 73.1 ±1.9 70.1 ±2.5 70.7 ±4.3\n",
      "SVM 74.2±5.0 73.2 ±3.5 71.3 ±4.0 73.1 ±5.7\n",
      "LPQ 1-NN 72.8 ±4.9 71.1 ±6.4 74.3±6.3 71.4 ±5.2\n",
      "QDA 70.4±1.1 69.3 ±4.2 67.2 ±1.9 68.3 ±1.8\n",
      "RF 73.8±5.0 72.3 ±5.5 73.4 ±5.9 71.1 ±3.8\n",
      "SVM 73.7±5.5 72.8 ±5.0 73.0 ±6.6 73.7±5.7\n",
      "ORB 1-NN 71.6±2.0 69.3 ±2.0 69.6 ±3.0 66.1 ±3.5\n",
      "QDA 74.4±1.7 66.5 ±3.2 63.5 ±2.7 63.5 ±2.2\n",
      "RF 72.3±1.8 69.3 ±1.0 68.6 ±1.7 67.6 ±1.2\n",
      "SVM 71.9±2.3 69.4 ±0.4 68.7 ±0.8 67.3 ±3.1\n",
      "PFTAS 1-NN 80.9 ±2.0 80.7±2.4 81.5±2.7 79.4 ±3.9\n",
      "QDA 83.8 ±4.1 82.1±4.9 84.2±4.1 82.0±5.9\n",
      "RF 81.8 ±2.0 81.3±2.8 83.5±2.3 81.0±3.8\n",
      "SVM 81.6 ±3.0 79.9±5.4 85.1±3.1 82.3±3.8\n",
      "Bold shows the best results over the magniﬁcation factors. For each magniﬁcation factor,\n",
      "underlining shows the ﬁve best results over the feature vectors and classiﬁers.\n",
      "Fig. 3. ROC curves for the confusion matrices presented in Table VII.\n",
      "required, which should be all the greater given that CLBP is high\n",
      "dimensional (1352).\n",
      "Over all the feature vectors, the PFTAS performs best. Since\n",
      "the best overall performance (recognition rate of 85.1% for fac-\n",
      "tor 200 ×) is achieved by the SVM trained with PFTAS descrip-\n",
      "tors, we focus on the SVM/PFTAS association and further an-\n",
      "alyze their performance, by drawing the associated ROC curve\n",
      "(see Fig. 3) and reporting the confusion matrices in Table VII,\n",
      "which conﬁrms that 200 seems to be the most discriminant mag-\n",
      "niﬁcation factor. As we can see, most of the confusions occur\n",
      "when a benign tumor is classiﬁed as malignant (high false pos-\n",
      "itive rate). This may be partially explained, as pointed out byTABLE VII\n",
      "-------------------\n",
      "\n",
      "CONFUSION MATRICES PRODUCED BY THE SVM C LASSIFIER TRAINED\n",
      "WITH THE PFTAS D ESCRIPTOR\n",
      "\n",
      "-------------------\n",
      "40× 100× 200× 400×\n",
      "-------------------\n",
      "\n",
      "BMBMBMBM\n",
      "\n",
      "-------------------\n",
      "B 0.62 0.38 0.38 0.62 0.75 0.25 0.75 0.25\n",
      "M 0.06 0.94 0.06 0.94 0.06 0.94 0.11 0.89\n",
      "B: benign, M: malignant.\n",
      "TABLE VIII\n",
      "ERROR DISTRIBUTION (%) OF THE SVM T RAINED WITHPFTAS O VER\n",
      "-------------------\n",
      "\n",
      "SUBCLASSES\n",
      "Class Subclass Magniﬁcation Factors\n",
      "\n",
      "-------------------\n",
      "40× 100× 200× 400×\n",
      "Benign Adenosis 15.7 21.7 9.7 10.3\n",
      "Fibroadenoma 28.5 31.8 29.5 30.2\n",
      "Phyllodes Tumor 13.6 18.6 10.1 14.4\n",
      "Tubular Adenoma 23.1 19.5 15.6 16.5\n",
      "Malignant Ductal 11.6 2.8 13.9 8.7\n",
      "Lobular 0.0 0.0 0.2 3.2\n",
      "Mucinous 2.8 5.1 13.9 10.1\n",
      "Papillary 4.7 0.5 7.1 6.6\n",
      "A large amount of false positive comes from ﬁbroadenoma (benign)\n",
      "mistaken for malignant tumor.\n",
      "Fig. 4. Example of misclassiﬁcation: (a) benign tumor classiﬁed as a malig-\n",
      "nant tumor and (b) real malignant tumor.\n",
      "Kowal et al. [9], by the fact that one of the benign tumor present\n",
      "in the dataset (ﬁbroadenoma) shares similar properties with a\n",
      "malignant tumor. To verify this hypothesis, we analyze the ori-\n",
      "gin of errors in the SVM/PFTAS results in Table VIII. This\n",
      "analysis shows that independently of the magniﬁcation factor,\n",
      "about 30% of errors of the classiﬁer are due to benign tumors\n",
      "ﬁbroadenoma classiﬁed as malignant class. One example of this\n",
      "misclassiﬁcation is presented in Fig. 4, where (a) shows a be-\n",
      "nign tumor classiﬁed as a malignant tumor and (b) presents a\n",
      "real malignant tumor.\n",
      "In spite of the complexity of the problem, a reliable CAD\n",
      "system should produce very low false positive and negative\n",
      "rates. This will be the main challenge for researchers willing\n",
      "to use the proposed dataset. One way to build a more reliable\n",
      "system is by combining the classiﬁers into a multiple classiﬁer\n",
      "system framework [35]. Another approach that has gained a\n",
      "lot of attention in the pattern recognition community recently\n",
      "is the dynamic selection of classiﬁers (DSC), which selects a\n",
      "different classiﬁer for each new test sample. DSC techniques\n",
      "rely on the assumption that each base classiﬁer is an expert\n",
      "Authorized licensed use limited to: DA IICT. Downloaded on December 13,2023 at 18:55:37 UTC from IEEE Xplore.  Restrictions apply. SPANHOL et al. : A DATASET FOR BREAST CANCER HISTOPATHOLOGICAL IMAGE CLASSIFICATION 1461\n",
      "Fig. 5. Feature space partitioned into three competence regions [36]. Blue\n",
      "lines delimit local region in which a competent classiﬁer can be found.\n",
      "in a different local region of the feature space. Based on this\n",
      "hypothesis, these techniques try to select the most competent\n",
      "classiﬁer for the local region in the feature space where the test\n",
      "sample is located.\n",
      "To show why classiﬁer selection works, we use the example\n",
      "presented by Kuncheva in [36]. Consider the two-class problem\n",
      "depicted in Fig. 5 and a pool Dof three weak classiﬁers, D=\n",
      "{D1,D2,D3}. Suppose that D1always predicts class “black”\n",
      "and that D2always predicts class “gray.” D3is a linear classiﬁer\n",
      "whose discriminant function is shown as the horizontal dashed\n",
      "line in Fig. 5. D3predicts class “black” for samples above the\n",
      "line and class “gray” for samples underneath. The individual\n",
      "accuracy of these classiﬁers is about 50%; therefore, the majority\n",
      "vote among them is useless as it will always match the decision\n",
      "of the arbiter D3and lead to 50% error. However, if we use the\n",
      "three local regions, delimited by the blue lines, and nominate\n",
      "the most competent classiﬁer for each region ( D1inR1,D2in\n",
      "R2,D3inR3), the error of the ensemble will be negligible.\n",
      "This example shows the potential of the DSC approach. In\n",
      "real life, it may be quite difﬁcult to ﬁnd regions that have such\n",
      "a huge impact on the ensemble performance [36]. The literature\n",
      "shows several different methods to deﬁne such regions. A recent\n",
      "review can be found in [37].\n",
      "To assess the potential of the DSC approach, i.e., to verify\n",
      "a given pool of classiﬁers is competent, a common method is\n",
      "to compute the accuracy of the oracle, which is the upper limit\n",
      "in terms of performance of the pool of classiﬁers. As stated in\n",
      "Section I, the oracle is an abstract model which always selects\n",
      "the classiﬁer that predicted the correct label, for a given query\n",
      "sample, if such a classiﬁer exists.\n",
      "A good oracle does not necessarily imply a good performance\n",
      "on a real-life classiﬁcation system. However, a DSC approach\n",
      "depends on a set of classiﬁers that are competent on different\n",
      "regions of the feature space; in other words, they depend on a\n",
      "good performance of the oracle.\n",
      "Using this abstract fusion model, Table IX shows the upper\n",
      "limit of the classiﬁers and representations adopted in this\n",
      "work. As we can see, despite of the intrinsic complexity\n",
      "of the problem, the performance of the oracle is very high.\n",
      "Considering a single architecture of classiﬁer trained with sixTABLE IX\n",
      "SUMMARY OF ACCURACY OF THE ORACLE (%)\n",
      "Classiﬁer Magniﬁcation factor\n",
      "40× 100× 200× 400×\n",
      "1-NN 91.5 91.5 93.1 91.5\n",
      "QDA 100 96.9 96.2 97.7\n",
      "RF 92.3 91.5 90.8 92.3\n",
      "SVM 95.4 95.4 94.6 97.7\n",
      "All classiﬁers 100 98.5 97.7 100\n",
      "The ﬁrst four lines show the oracle for each classi-\n",
      "ﬁer using six different representations. The last line\n",
      "reports the oracle considering all the 24 classiﬁers\n",
      "reported in Table VI.\n",
      "TABLE X\n",
      "-------------------\n",
      "\n",
      "HYPOTHETICAL CONFUSION MATRICES FOR THE ORACLE\n",
      "\n",
      "-------------------\n",
      "40× 100× 200× 400×\n",
      "-------------------\n",
      "\n",
      "BMBMBMBM\n",
      "\n",
      "-------------------\n",
      "B 1.00 0.00 1.00 0.00 0.88 0.12 1.00 0.00\n",
      "M 0.00 1.00 0.00 1.00 0.00 1.00 0.00 1.00\n",
      "B: benign, M: malignant.\n",
      "different representations, the upper limit of the system achieves\n",
      "93.9% in average, except for the QDA classiﬁer that reaches\n",
      "100% for the subset of 40 ×magniﬁcation images. Considering\n",
      "all the architectures and representations (24 experts), the\n",
      "upper limit increases up to 99% in average. Note that for the\n",
      "both magniﬁcation factors of 40 ×and 400 ×, all test images\n",
      "could be correctly classiﬁed by at least one of the classiﬁers\n",
      "in the pool.\n",
      "Table X presents the hypothetical confusion matrices for the\n",
      "oracle. As we can see, the proposed pool of classiﬁers is able to\n",
      "solve most of the confusions. The challenge now lies in deﬁning\n",
      "a winner strategy to select the classiﬁers given an input image.\n",
      "-------------------\n",
      "\n",
      "V. C ONCLUSION\n",
      "\n",
      "-------------------\n",
      "In this paper, we have presented a dataset of BC histopathol-\n",
      "ogy images called BreaKHis, which we make available to the\n",
      "scientiﬁc community, and a companion protocol (i.e., the folds)\n",
      "for two-class classiﬁcation of benign versus malignant im-\n",
      "ages. We have performed some ﬁrst experiments involving six\n",
      "state-of-the-art feature vectors and four classiﬁers. They have\n",
      "shown room for improvement is left, but also that the comple-\n",
      "mentarity of the magniﬁcation factors should be investigated\n",
      "in the future, to design a possible coarse-to-ﬁne strategy for\n",
      "processing the different magniﬁcation factor images. One may\n",
      "also consider that different features should be used to describe\n",
      "the different magniﬁcation factors. The oracle results also show\n",
      "that a single-classiﬁer might not be enough, and that designing a\n",
      "strategy to combine or select the classiﬁers given an input image\n",
      "should help to increase the accuracy.\n",
      "Additional challenges include multiclass classiﬁcation for\n",
      "both the malignant and the benign image sets. Also, the high\n",
      "Authorized licensed use limited to: DA IICT. Downloaded on December 13,2023 at 18:55:37 UTC from IEEE Xplore.  Restrictions apply. 1462 IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 7, JULY 2016\n",
      "false positive rate that we have highlighted in this work may be\n",
      "decreased by implementing a rejection scheme.\n",
      "By making this dataset available for research purposes, we\n",
      "hope to foster research in computer-aided diagnosis for BC\n",
      "histopathology, and also in ensemble classiﬁcation by providing\n",
      "a real life, challenging dataset. Future studies may provide some\n",
      "feedback to the pathologist, so as to help him analyzing these\n",
      "images and deﬁning a strategy to identify areas to be explored.\n",
      "-------------------\n",
      "\n",
      "ACKNOWLEDGMENT\n",
      "\n",
      "-------------------\n",
      "The authors would ﬁrst like to thank the valuable collabo-\n",
      "ration of P&D Laboratory-Brazil, for providing the slide col-\n",
      "lection of histopathological studies of breast tissue used in the\n",
      "preparation of the presented image database. In particular, they\n",
      "would like to acknowledge and thank the pathologists F. Ne-\n",
      "gretti and F. S. Rechia of P&D, for their valuable feedback\n",
      "throughout the revision process. Also, they would like to thank\n",
      "C. E. Pokes, a medical student from the State University of\n",
      "West Parana (UNIOESTE), for his great commitment to the\n",
      "digitization process. Finally, the authors would like to thank\n",
      "the reviewers and editors for their very helpful suggestions and\n",
      "insightful comments which have resulted in an improved paper.\n",
      "-------------------\n",
      "\n",
      "REFERENCES\n",
      "\n",
      "-------------------\n",
      "[1] P. Boyle and B. Levin, Eds., World Cancer Report 2008. Lyon:\n",
      "IARC, 2008. [Online]. Available: http://www.iarc.fr/en/publications/pdfs-\n",
      "online/wcr/2008/wcr_2008.pdf\n",
      "[ 2 ] J .E .J o y et al. ,E d s . , Saving Women’s Lives: Strategies for Improving\n",
      "Breast Cancer Detection and Diagnosis . Washington, DC, USA: Natl.\n",
      "Acad. Press, 2005.\n",
      "[3] B. Stenkvist et al. , “Computerized nuclear morphometry as an objective\n",
      "method for characterizing human cancer cell populations,” Cancer Res. ,\n",
      "vol. 38, no. 12, pp. 4688–4697, 1978.\n",
      "[4] Breastcancer.org. (2012) Biopsy. [Online]. Available: http://www.\n",
      "breastcancer.org/symptoms/testing/types/biopsy\n",
      "[5] R. Rubin et al. ,E d s . , Rubin’s Pathology Clinicopathologic Foundations\n",
      "of Medicine , 6th ed., Philadelphia, PA, USA: Williams & Wilkins, 2012.\n",
      "[6] S. R. Lakhani et al. ,WHO Classiﬁcation of Tumours of the Breast , 4th ed.\n",
      "Lyon, France: WHO Press, 2012.\n",
      "[7] M. N. Gurcan et al. , “Histopathological image analysis: A review,” IEEE\n",
      "Rev. Biomed. Eng. , vol. 2, pp. 147–171, 2009.\n",
      "[8] C. Desir et al. , “Classiﬁcation of endomicroscopic images of the lung\n",
      "based on random subwindows and extra-trees,” IEEE Trans. Biomed. Eng. ,\n",
      "vol. 59, no. 9, pp. 2677–2683, Sep. 2012.\n",
      "[9] M. Kowal et al. , “Computer-aided diagnosis of breast cancer based on ﬁne\n",
      "needle biopsy microscopic images,” Comput. Biol. Med. , vol. 43, no. 10,\n",
      "pp. 1563–1572, 2013.\n",
      "[10] P. Filipczuk et al. , “Computer-aided breast cancer diagnosis based on the\n",
      "analysis of cytological images of ﬁne needle biopsies,” IEEE Trans. Med.\n",
      "Imag. , vol. 32, no. 12, pp. 2169–2178, Dec. 2013.\n",
      "[11] Y . M. George et al. , “Remote computer-aided breast cancer detection\n",
      "and diagnosis system based on cytological images,” IEEE Syst. J. ,v o l .8 ,\n",
      "no. 3, pp. 949–964, Sep. 2014.\n",
      "[12] Y . Zhang et al. , “Breast cancer diagnosis from biopsy images with highly\n",
      "reliable random subspace classiﬁer ensembles,” Mach. Vision Appl. ,\n",
      "vol. 24, no. 7, pp. 1405–1420, 2013.\n",
      "[13] Y . Zhang et al. , “One-class kernel subspace ensemble for medical im-\n",
      "age classiﬁcation,” EURASIP J. Adv. Signal Process. , vol. 2014, no. 17,\n",
      "pp. 1–13, 2014.[14] M. Veta et al. , “Breast cancer histopathology image analysis: A re-\n",
      "view,” IEEE Trans. Biomed. Eng. , vol. 61, no. 5, pp. 1400–1411,\n",
      "May 2014.\n",
      "[15] L. I. Kuncheva, “A theoretical study on six classiﬁer fusion strategies,”\n",
      "IEEE Trans. Pattern Anal. Mach. Intell. , vol. 24, no. 2, pp. 281–286,\n",
      "Feb. 2002.\n",
      "[16] A. L. Mescher, Junqueiras Basic Histology: Text and Atlas .N e wY o r k ,\n",
      "NY , USA: McGraw-Hill, 2013.\n",
      "[17] T. Ojala et al. , “Multiresolution gray-scale and rotation invariant texture\n",
      "classiﬁcation with local binary patterns,” IEEE Trans. Pattern Anal. Mach.\n",
      "Intell. , vol. 24, no. 7, pp. 971–987, Jul. 2002.\n",
      "[18] Z. Guo et al. , “A completed modeling of local binary pattern operator\n",
      "for texture classiﬁcation,” IEEE Trans. Image Process. , vol. 19, no. 6,\n",
      "pp. 1657–1663, Jun. 2010.\n",
      "[19] V . Ojansivu and J. Heikkil ¨a, “Blur insensitive texture classiﬁcation using\n",
      "local phase quantization,” in Proc. 3rd Int. Conf. Image Signal Process. ,\n",
      "2008, vol. 5099, pp. 236–243.\n",
      "[20] R. Haralick et al. , “Textural features for image classiﬁcation,” IEEE Trans.\n",
      "Syst. Man Cybern. , vol. SMC-3, no. 6, pp. 610–621, Nov. 1973.\n",
      "[21] N. A. Hamilton, et al. (2007). Fast automated cell phenotype\n",
      "image classiﬁcation. BMC Bioinformatics .8. [Online]. Available:\n",
      "http://www.biomedcentral.com/1471-2105/8/110\n",
      "[22] E. Rublee et al. , “ORB: An efﬁcient alternative to SIFT or SURF,” in\n",
      "Proc. IEEE Int. Conf. Comput. Vision , 2011, pp. 2564–2571.\n",
      "[23] J. Martins et al. , “Forest species recognition based on dynamic classiﬁer\n",
      "selection and dissimilarity feature vector representation,” Mach. Vision\n",
      "Appl. , vol. 26, no. 2, pp. 279–293, 2015.\n",
      "[24] J. Paivarinta et al. , “V olume local phase quantization for blur-insensitive\n",
      "dynamic texture classiﬁcation,” in Proc. 17th Scandinavian Conf. Image\n",
      "Anal. , 2011, pp. 360–369.\n",
      "[25] L. P. Coelho et al. , “Structured literature image ﬁnder: extracting infor-\n",
      "mation from text and images in biomedical literature,” in Linking Liter-\n",
      "ature, Information, and Knowledge for Biology (ser. LNCS) vol. 6004,\n",
      "C. Blaschke and H. Shatkay, Eds. New York, NY , USA: Springer, 2010,\n",
      "pp. 23–32.\n",
      "[26] D. G. Lowe, “Object recognition from local scale-invariant features,” in\n",
      "Proc. IEEE Int. Conf. Comput. Vision , Sep. 1999, vol. 2, pp. 1150–1157.\n",
      "[27] H. Bay et al. , “Surf: Speeded up robust features,” in Proc. 9th Eur. Conf.\n",
      "Comput. Vision , May 2006, pp. 404–417.\n",
      "[28] E. Rosten et al. , “Faster and better: A machine learning approach to\n",
      "corner detection,” IEEE Trans. Pattern Anal. Mach. Intell. , vol. 32, no. 1,\n",
      "pp. 105–119, Jan. 2010.\n",
      "[29] M. Calonder et al. , “BRIEF:binary robust independent elementary fea-\n",
      "tures,” in Proc. Eur. Conf. Comput. Vision , 2010, pp. 778–792.\n",
      "[30] G. Bradski, “The OpenCV library,” Dr. Dobb’s Journal of Software Tools ,\n",
      "2000, vol. 25(11), pp. 120–125.\n",
      "[31] C. Cortes and V . Vapnik, “Suport-vector networks,” Mach. Learning ,\n",
      "vol. 20, pp. 273–297, 1995.\n",
      "[32] L. Breiman, “Random forests,” Mach. Learning , vol. 45, no. 1, pp. 5–32,\n",
      "2001.\n",
      "[33] F. Pedregosa et al. , “Scikit-learn: Machine learning in Python,” J. Mach.\n",
      "Learning Res. , vol. 12, pp. 2825–2830, 2011.\n",
      "[34] T. Fawcett, “An introduction to ROC analysis,” Pattern Recog. Lett. ,\n",
      "vol. 27, pp. 861–874, 2006.\n",
      "[35] J. Kittler et al. , “On combining classiﬁers,” IEEE Trans. Pattern Anal.\n",
      "Mach. Intell. , vol. 20, no. 3, pp. 226–239, Mar. 1998.\n",
      "[36] L. Kuncheva, Combining Pattern Classiﬁers: Methods and Algorithms ,\n",
      "2nd ed. New York, NY , USA: Wiley, 2014.\n",
      "[37] A. S. Britto Jr., R. Sabourin, and L. S. Oliveira, “Dynamic selection of\n",
      "classiﬁers—A comprehensive review,” Pattern Recognitional , vol. 47, no.\n",
      "11, pp. 3665–3680, 2014.\n",
      "Authors’ photographs and biographies not available at the time of publication.\n",
      "Authorized licensed use limited to: DA IICT. Downloaded on December 13,2023 at 18:55:37 UTC from IEEE Xplore.  Restrictions apply. \n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    pdf_file_obj = open(file_path, 'rb')\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file_obj)\n",
    "    num_pages = len(pdf_reader.pages)\n",
    "    text = ''\n",
    "    for page_num in range(num_pages):\n",
    "        page_obj = pdf_reader.pages[page_num]\n",
    "        text += page_obj.extract_text()\n",
    "    pdf_file_obj.close()\n",
    "    return text\n",
    "import json\n",
    "file_path = r'C:\\Users\\Kunj R. Patel\\Desktop\\codes\\python\\extra\\p3.pdf'\n",
    "text = extract_text_from_pdf(file_path)\n",
    "def extract_sections(text):\n",
    "    sections = re.split(r'(\\n(?!TABLE\\s)(?:[A-Z]\\.\\s)?(?:[IVXLCDM]+\\.\\s)?(?:[A-Z]\\w*(?:\\s+[A-Z]\\w*)*(?:-\\w+)*)\\n)', text)\n",
    "    for s in sections:\n",
    "        print(s)\n",
    "        print('-------------------')\n",
    "    section_dict = {}\n",
    "    section_dict['header'] = sections[0].strip()\n",
    "    for i in range(1, len(sections)-1, 2):\n",
    "         section_dict[sections[i].strip()] = sections[i+1].strip()\n",
    "    return section_dict\n",
    "\n",
    "json_text = json.dumps(extract_sections(text), indent=4)\n",
    "with open('p3.json', 'w') as f:\n",
    "    f.write(json_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
