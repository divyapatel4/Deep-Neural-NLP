{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4298,"sourceType":"modelInstanceVersion","modelInstanceId":3093}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installations, imports, utils","metadata":{}},{"cell_type":"code","source":"!pip install transformers==4.33.0 accelerate==0.22.0 einops==0.6.1 langchain==0.0.300 xformers==0.0.21 \\\nbitsandbytes==0.41.1 sentence_transformers==2.2.2 chromadb==0.4.12","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-13T19:26:08.748731Z","iopub.execute_input":"2023-12-13T19:26:08.749127Z","iopub.status.idle":"2023-12-13T19:29:51.458330Z","shell.execute_reply.started":"2023-12-13T19:26:08.749088Z","shell.execute_reply":"2023-12-13T19:29:51.457106Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting transformers==4.33.0\n  Obtaining dependency information for transformers==4.33.0 from https://files.pythonhosted.org/packages/e1/9d/4d9fe5c3b820db10773392ac5f4a0c8dab668f70b245ce2ce09785166128/transformers-4.33.0-py3-none-any.whl.metadata\n  Downloading transformers-4.33.0-py3-none-any.whl.metadata (119 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting accelerate==0.22.0\n  Obtaining dependency information for accelerate==0.22.0 from https://files.pythonhosted.org/packages/4d/a7/05c67003d659a0035f2b3a8cf389c1d9645865aee84a73ce99ddab16682f/accelerate-0.22.0-py3-none-any.whl.metadata\n  Downloading accelerate-0.22.0-py3-none-any.whl.metadata (17 kB)\nCollecting einops==0.6.1\n  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting langchain==0.0.300\n  Obtaining dependency information for langchain==0.0.300 from https://files.pythonhosted.org/packages/af/63/7739b90f16cc347e70921b429208e164fb9889a732dd802e36a6185db9cc/langchain-0.0.300-py3-none-any.whl.metadata\n  Downloading langchain-0.0.300-py3-none-any.whl.metadata (15 kB)\nCollecting xformers==0.0.21\n  Obtaining dependency information for xformers==0.0.21 from https://files.pythonhosted.org/packages/c7/b4/9f8bea4204f8482c9c9c64bcf86bd209ccfb2ebdb27e3590ef4c1e87b743/xformers-0.0.21-cp310-cp310-manylinux2014_x86_64.whl.metadata\n  Downloading xformers-0.0.21-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\nCollecting bitsandbytes==0.41.1\n  Obtaining dependency information for bitsandbytes==0.41.1 from https://files.pythonhosted.org/packages/1e/2c/af22cd797fc368a9f098ed03015730e6568b884fe67f9940793d944a4b7b/bitsandbytes-0.41.1-py3-none-any.whl.metadata\n  Downloading bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\nCollecting sentence_transformers==2.2.2\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting chromadb==0.4.12\n  Obtaining dependency information for chromadb==0.4.12 from https://files.pythonhosted.org/packages/4d/74/01146afe0892cf863c9a1af3924d4fcb1e317e3982760435b434db7eadcc/chromadb-0.4.12-py3-none-any.whl.metadata\n  Downloading chromadb-0.4.12-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (0.19.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (2.31.0)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.33.0)\n  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0) (2.0.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (2.0.20)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (3.8.5)\nRequirement already satisfied: anyio<4.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (3.7.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (0.6.3)\nCollecting jsonpatch<2.0,>=1.33 (from langchain==0.0.300)\n  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\nCollecting langsmith<0.1.0,>=0.0.38 (from langchain==0.0.300)\n  Obtaining dependency information for langsmith<0.1.0,>=0.0.38 from https://files.pythonhosted.org/packages/ea/09/e1458ea0a26037740aac27319479aaa79053a06413b5d715d56d37371b55/langsmith-0.0.69-py3-none-any.whl.metadata\n  Downloading langsmith-0.0.69-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (2.8.7)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (1.10.12)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (8.2.3)\nCollecting torch>=1.10.0 (from accelerate==0.22.0)\n  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.15.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.11.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.1.99)\nCollecting chroma-hnswlib==0.7.3 (from chromadb==0.4.12)\n  Obtaining dependency information for chroma-hnswlib==0.7.3 from https://files.pythonhosted.org/packages/2f/48/f7609a3cb15a24c5d8ec18911ce10ac94144e9a89584f0a86bf9871b024c/chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\nCollecting fastapi<0.100.0,>=0.95.2 (from chromadb==0.4.12)\n  Obtaining dependency information for fastapi<0.100.0,>=0.95.2 from https://files.pythonhosted.org/packages/73/eb/03b691afa0b5ffa1e93ed34f97ec1e7855c758efbdcfb16c209af0b0506b/fastapi-0.99.1-py3-none-any.whl.metadata\n  Downloading fastapi-0.99.1-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: uvicorn[standard]>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (0.23.2)\nCollecting posthog>=2.4.0 (from chromadb==0.4.12)\n  Obtaining dependency information for posthog>=2.4.0 from https://files.pythonhosted.org/packages/3b/82/441cb77a43499661228048dcd0d21e0ae3235b442d0f1b9b606e29c2a5ed/posthog-3.1.0-py2.py3-none-any.whl.metadata\n  Downloading posthog-3.1.0-py2.py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (4.5.0)\nCollecting pulsar-client>=3.1.0 (from chromadb==0.4.12)\n  Obtaining dependency information for pulsar-client>=3.1.0 from https://files.pythonhosted.org/packages/b7/54/ef01474b40f70f59b459497bdd48a28fc582c0cde1914fa3efa53053a23e/pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\nCollecting onnxruntime>=1.14.1 (from chromadb==0.4.12)\n  Obtaining dependency information for onnxruntime>=1.14.1 from https://files.pythonhosted.org/packages/7a/cf/6aa8c56fd63f53c2c485921e411269c7b501a2b4e634bd02f226ab2d5d8e/onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nCollecting pypika>=0.48.9 (from chromadb==0.4.12)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting overrides>=7.3.1 (from chromadb==0.4.12)\n  Obtaining dependency information for overrides>=7.3.1 from https://files.pythonhosted.org/packages/da/28/3fa6ef8297302fc7b3844980b6c5dbc71cdbd4b61e9b2591234214d5ab39/overrides-7.4.0-py3-none-any.whl.metadata\n  Downloading overrides-7.4.0-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (5.13.0)\nCollecting bcrypt>=4.0.1 (from chromadb==0.4.12)\n  Obtaining dependency information for bcrypt>=4.0.1 from https://files.pythonhosted.org/packages/af/82/96ffdbe0f56b12db0da8f1a9c869399d22231ed1313a84ea2ddc6381a498/bcrypt-4.1.1-cp37-abi3-manylinux_2_28_x86_64.whl.metadata\n  Downloading bcrypt-4.1.1-cp37-abi3-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\nRequirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (0.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (3.1.2)\nCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting triton==2.0.0 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.22.0) (68.1.2)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.22.0) (0.41.2)\nCollecting cmake (from triton==2.0.0->torch>=1.10.0->accelerate==0.22.0)\n  Obtaining dependency information for cmake from https://files.pythonhosted.org/packages/0f/92/69c0ff59697c8f8199283b35d6f3be575e52526d65894330f25e9933f31b/cmake-3.28.0-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n  Downloading cmake-3.28.0-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\nCollecting lit (from triton==2.0.0->torch>=1.10.0->accelerate==0.22.0)\n  Downloading lit-17.0.6.tar.gz (153 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.3.1)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.300) (3.4)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.300) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.300) (1.1.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (3.20.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (0.9.0)\nRequirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from fastapi<0.100.0,>=0.95.2->chromadb==0.4.12) (0.27.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.0) (2023.12.1)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.300) (2.0)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.4.12)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.12) (23.5.26)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.12) (3.20.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.33.0) (3.0.9)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.12) (1.16.0)\nCollecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.4.12)\n  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nRequirement already satisfied: backoff>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.12) (2.2.1)\nRequirement already satisfied: python-dateutil>2.1 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.12) (2.8.2)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from pulsar-client>=3.1.0->chromadb==0.4.12) (2023.11.17)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0) (1.26.15)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.300) (2.0.2)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb==0.4.12) (8.1.7)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.14.0)\nRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.6.1)\nRequirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (1.0.0)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.19.0)\nRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.21.0)\nRequirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (12.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.2.2) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.2.2) (3.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers==2.2.2) (10.1.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (1.0.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.12)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.22.0) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.22.0) (1.3.0)\nDownloading transformers-4.33.0-py3-none-any.whl (7.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain-0.0.300-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.21-cp310-cp310-manylinux2014_x86_64.whl (167.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.0/167.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading chromadb-0.4.12-py3-none-any.whl (426 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.5/426.5 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bcrypt-4.1.1-cp37-abi3-manylinux_2_28_x86_64.whl (699 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m699.4/699.4 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.99.1-py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nDownloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading overrides-7.4.0-py3-none-any.whl (17 kB)\nDownloading posthog-3.1.0-py2.py3-none-any.whl (37 kB)\nDownloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading cmake-3.28.0-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/26.3 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hBuilding wheels for collected packages: sentence_transformers, pypika, lit\n  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=d0fa7859086d447d366395c8258dd4d4e30393b7ada9f090f895aeb6c6f455ac\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=553bc7a92b5ca46aa3ebe593e3aabd89aa5c945660e28d769fee854d4ae3c441\n  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=80e44962ec221782575d0e75c83a84f6613cf561996613930cac33fe2d994db9\n  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\nSuccessfully built sentence_transformers pypika lit\nInstalling collected packages: tokenizers, pypika, monotonic, lit, cmake, bitsandbytes, pulsar-client, overrides, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, jsonpatch, humanfriendly, einops, chroma-hnswlib, bcrypt, posthog, nvidia-cusolver-cu11, nvidia-cudnn-cu11, langsmith, coloredlogs, transformers, onnxruntime, fastapi, langchain, chromadb, triton, torch, xformers, sentence_transformers, accelerate\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.0\n    Uninstalling tokenizers-0.15.0:\n      Successfully uninstalled tokenizers-0.15.0\n  Attempting uninstall: overrides\n    Found existing installation: overrides 6.5.0\n    Uninstalling overrides-6.5.0:\n      Successfully uninstalled overrides-6.5.0\n  Attempting uninstall: jsonpatch\n    Found existing installation: jsonpatch 1.32\n    Uninstalling jsonpatch-1.32:\n      Successfully uninstalled jsonpatch-1.32\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.35.2\n    Uninstalling transformers-4.35.2:\n      Successfully uninstalled transformers-4.35.2\n  Attempting uninstall: fastapi\n    Found existing installation: fastapi 0.101.1\n    Uninstalling fastapi-0.101.1:\n      Successfully uninstalled fastapi-0.101.1\n  Attempting uninstall: torch\n    Found existing installation: torch 2.0.0\n    Uninstalling torch-2.0.0:\n      Successfully uninstalled torch-2.0.0\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.25.0\n    Uninstalling accelerate-0.25.0:\n      Successfully uninstalled accelerate-0.25.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-pubsublite 1.8.3 requires overrides<7.0.0,>=6.0.1, but you have overrides 7.4.0 which is incompatible.\njupyterlab 4.0.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.1 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.5 which is incompatible.\nkaggle-environments 1.14.3 requires transformers>=4.33.1, but you have transformers 4.33.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.22.0 bcrypt-4.1.1 bitsandbytes-0.41.1 chroma-hnswlib-0.7.3 chromadb-0.4.12 cmake-3.28.0 coloredlogs-15.0.1 einops-0.6.1 fastapi-0.99.1 humanfriendly-10.0 jsonpatch-1.33 langchain-0.0.300 langsmith-0.0.69 lit-17.0.6 monotonic-1.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 onnxruntime-1.16.3 overrides-7.4.0 posthog-3.1.0 pulsar-client-3.3.0 pypika-0.48.9 sentence_transformers-2.2.2 tokenizers-0.13.3 torch-2.0.1 transformers-4.33.0 triton-2.0.0 xformers-0.0.21\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/zaytoun/scihub.py.git\n!pip install -r /kaggle/working/scihub.py/requirements.txt\n!pip install pdfminer.six","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:29:51.460329Z","iopub.execute_input":"2023-12-13T19:29:51.461077Z","iopub.status.idle":"2023-12-13T19:30:20.230320Z","shell.execute_reply.started":"2023-12-13T19:29:51.461039Z","shell.execute_reply":"2023-12-13T19:30:20.229222Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'scihub.py'...\nremote: Enumerating objects: 108, done.\u001b[K\nremote: Counting objects: 100% (29/29), done.\u001b[K\nremote: Compressing objects: 100% (6/6), done.\u001b[K\nremote: Total 108 (delta 27), reused 23 (delta 23), pack-reused 79\u001b[K\nReceiving objects: 100% (108/108), 21.43 KiB | 1.43 MiB/s, done.\nResolving deltas: 100% (50/50), done.\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/scihub.py/requirements.txt (line 1)) (4.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/scihub.py/requirements.txt (line 2)) (2.31.0)\nRequirement already satisfied: retrying in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/scihub.py/requirements.txt (line 3)) (1.3.3)\nRequirement already satisfied: pysocks in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/scihub.py/requirements.txt (line 4)) (1.7.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->-r /kaggle/working/scihub.py/requirements.txt (line 1)) (2.3.2.post1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->-r /kaggle/working/scihub.py/requirements.txt (line 2)) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->-r /kaggle/working/scihub.py/requirements.txt (line 2)) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->-r /kaggle/working/scihub.py/requirements.txt (line 2)) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->-r /kaggle/working/scihub.py/requirements.txt (line 2)) (2023.11.17)\nRequirement already satisfied: six>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from retrying->-r /kaggle/working/scihub.py/requirements.txt (line 3)) (1.16.0)\nCollecting pdfminer.six\n  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six) (3.2.0)\nRequirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six) (40.0.2)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\nInstalling collected packages: pdfminer.six\nSuccessfully installed pdfminer.six-20221105\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport subprocess\nfrom pdfminer.high_level import extract_pages\nfrom pdfminer.layout import LTTextContainer\n\ndef get_pdfs(dois, output_file_path):\n        os.mkdir(output_file_path)\n        cnt = 0\n        for d in dois:\n            cmd = [\"python\", \"/kaggle/working/scihub.py/scihub/scihub.py\", \"--download\", d, \"--output\", output_file_path]\n            result = subprocess.run(cmd)\n            if (result.returncode == 0):cnt += 1\n        for file_name in os.listdir(output_file_path):\n            # Check if the file is a PDF\n            if file_name.endswith(\".pdf\"):\n                # Construct the full file path\n                file_path = os.path.join(output_file_path, file_name)\n                # Construct the output file path\n                output_file_path_txt = os.path.join(output_file_path, file_name.replace('.pdf', '.txt'))\n                # Open the output file\n                with open(output_file_path_txt, 'w') as output_file:\n                    # Extract text from the PDF\n                    for page_layout in extract_pages(file_path):\n                        for element in page_layout:\n                            if isinstance(element, LTTextContainer):\n                                # Write the text to the output file instead of printing it\n                                output_file.write(element.get_text())\n                                output_file.write(\"---------------------\\n\")\n        return cnt\n","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:30:20.231882Z","iopub.execute_input":"2023-12-13T19:30:20.232301Z","iopub.status.idle":"2023-12-13T19:30:20.283287Z","shell.execute_reply.started":"2023-12-13T19:30:20.232263Z","shell.execute_reply":"2023-12-13T19:30:20.282603Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"get_pdfs([\"10.1007/s00464-020-07404-y\"], \"./output\")\n!rm -rf ./output","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:30:20.285179Z","iopub.execute_input":"2023-12-13T19:30:20.285446Z","iopub.status.idle":"2023-12-13T19:30:23.619262Z","shell.execute_reply.started":"2023-12-13T19:30:20.285422Z","shell.execute_reply":"2023-12-13T19:30:23.617957Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\nfrom pdfminer.high_level import extract_pages\nfrom pdfminer.layout import LTTextContainer\n\ndef convert_pdfs(input_folder_path, output_folder_path):\n    # Create the output folder if it doesn't exist\n    os.makedirs(output_folder_path, exist_ok=True)\n    \n    for file_name in os.listdir(input_folder_path):\n        # Check if the file is a PDF\n        if file_name.endswith(\".pdf\"):\n            # Construct the full file path\n            file_path = os.path.join(input_folder_path, file_name)\n            # Construct the output file path\n            output_file_path = os.path.join(output_folder_path, file_name.replace('.pdf', '.txt'))\n            # Open the output file\n            with open(output_file_path, 'w') as output_file:\n                # Extract text from the PDF\n                for page_layout in extract_pages(file_path):\n                    for element in page_layout:\n                        if isinstance(element, LTTextContainer):\n                            # Write the text to the output file instead of printing it\n                            output_file.write(element.get_text())\n                            output_file.write(\"---------------------\\n\")\n\nconvert_pdfs('/kaggle/input/samplepdfsnlp', '/kaggle/working/texts')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:30:23.620828Z","iopub.execute_input":"2023-12-13T19:30:23.621183Z","iopub.status.idle":"2023-12-13T19:33:03.818859Z","shell.execute_reply.started":"2023-12-13T19:30:23.621152Z","shell.execute_reply":"2023-12-13T19:33:03.818019Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from torch import cuda, bfloat16\nimport torch\nimport transformers\nfrom transformers import AutoTokenizer\nfrom time import time\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.chains import LLMChain, SimpleSequentialChain\nfrom langchain.chains import RetrievalQA\nfrom langchain.vectorstores import Chroma\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-13T19:33:03.820264Z","iopub.execute_input":"2023-12-13T19:33:03.821068Z","iopub.status.idle":"2023-12-13T19:33:10.592986Z","shell.execute_reply.started":"2023-12-13T19:33:03.821032Z","shell.execute_reply":"2023-12-13T19:33:10.592125Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Initialize model, tokenizer, query pipeline","metadata":{}},{"cell_type":"code","source":"model_id = '/kaggle/input/llama-2/pytorch/7b-chat-hf/1'\n\ndevice = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n\n# set quantization configuration to load large model with less GPU memory\n# this requires the `bitsandbytes` library\nbnb_config = transformers.BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type='nf4',\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=bfloat16\n)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-13T19:33:10.594158Z","iopub.execute_input":"2023-12-13T19:33:10.594579Z","iopub.status.idle":"2023-12-13T19:33:10.638547Z","shell.execute_reply.started":"2023-12-13T19:33:10.594553Z","shell.execute_reply":"2023-12-13T19:33:10.637698Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Prepare the model and the tokenizer.","metadata":{}},{"cell_type":"code","source":"time_1 = time()\nmodel_config = transformers.AutoConfig.from_pretrained(\n    model_id,\n)\nmodel = transformers.AutoModelForCausalLM.from_pretrained(\n    model_id,\n    trust_remote_code=True,\n    config=model_config,\n    quantization_config=bnb_config,\n    device_map='auto',\n)\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ntime_2 = time()\nprint(f\"Prepare model, tokenizer: {round(time_2-time_1, 3)} sec.\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-13T19:33:10.639638Z","iopub.execute_input":"2023-12-13T19:33:10.639909Z","iopub.status.idle":"2023-12-13T19:37:00.310803Z","shell.execute_reply.started":"2023-12-13T19:33:10.639885Z","shell.execute_reply":"2023-12-13T19:37:00.309736Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1585b300918f402b9bba8e1d5b4cad1b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Prepare model, tokenizer: 229.645 sec.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Define the query pipeline.","metadata":{}},{"cell_type":"code","source":"time_1 = time()\nquery_pipeline = transformers.pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",)\ntime_2 = time()\nprint(f\"Prepare pipeline: {round(time_2-time_1, 3)} sec.\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-13T19:37:00.311983Z","iopub.execute_input":"2023-12-13T19:37:00.312295Z","iopub.status.idle":"2023-12-13T19:37:02.108565Z","shell.execute_reply.started":"2023-12-13T19:37:00.312269Z","shell.execute_reply":"2023-12-13T19:37:02.107602Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Prepare pipeline: 1.791 sec.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We define a function for testing the pipeline.","metadata":{}},{"cell_type":"code","source":"def test_model(tokenizer, pipeline, prompt_to_test):\n    \"\"\"\n    Perform a query\n    print the result\n    Args:\n        tokenizer: the tokenizer\n        pipeline: the pipeline\n        prompt_to_test: the prompt\n    Returns\n        None\n    \"\"\"\n    # adapted from https://huggingface.co/blog/llama2#using-transformers\n    time_1 = time()\n    sequences = pipeline(\n        prompt_to_test,\n        do_sample=True,\n        top_k=10,\n        num_return_sequences=1,\n        eos_token_id=tokenizer.eos_token_id,\n        max_length=200,)\n    time_2 = time()\n    print(f\"Test inference: {round(time_2-time_1, 3)} sec.\")\n    for seq in sequences:\n        print(f\"Result: {seq['generated_text']}\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-13T19:37:02.111741Z","iopub.execute_input":"2023-12-13T19:37:02.112452Z","iopub.status.idle":"2023-12-13T19:37:02.117943Z","shell.execute_reply.started":"2023-12-13T19:37:02.112423Z","shell.execute_reply":"2023-12-13T19:37:02.117087Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Test the query pipeline\n\nWe test the pipeline with a query about the meaning of State of the Union (SOTU).","metadata":{}},{"cell_type":"code","source":"test_model(tokenizer,\n           query_pipeline,\n           \"Please explain what is the State of the Union address. Give just a definition. Keep it in 100 words.\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-13T19:37:02.119158Z","iopub.execute_input":"2023-12-13T19:37:02.119422Z","iopub.status.idle":"2023-12-13T19:37:11.839521Z","shell.execute_reply.started":"2023-12-13T19:37:02.119398Z","shell.execute_reply":"2023-12-13T19:37:11.838595Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Test inference: 9.702 sec.\nResult: Please explain what is the State of the Union address. Give just a definition. Keep it in 100 words. A State of the Union (SotU) adress is a speech given by the U.S.President to a joint session of Congress, outlining the condition of the union and the legislative agenda for the coming year. It is an annual tradition established in 1801 and provides an opportunity for the President to communicate directly with the American people and Congress about the current state of affairs in the nation.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Retrieval Augmented Generation","metadata":{}},{"cell_type":"markdown","source":"## Check the model with a HuggingFace pipeline\n\n\nWe check the model with a HF pipeline, using a query about the meaning of State of the Union (SOTU).","metadata":{"execution":{"iopub.status.busy":"2023-09-23T19:22:16.433666Z","iopub.execute_input":"2023-09-23T19:22:16.434937Z","iopub.status.idle":"2023-09-23T19:22:16.440864Z","shell.execute_reply.started":"2023-09-23T19:22:16.434891Z","shell.execute_reply":"2023-09-23T19:22:16.439217Z"}}},{"cell_type":"code","source":"llm = HuggingFacePipeline(pipeline=query_pipeline)\n# checking again that everything is working fine\nllm(prompt=\"Please explain what is the State of the Union address. Give just a definition. Keep it in 100 words.\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-13T19:37:11.840864Z","iopub.execute_input":"2023-12-13T19:37:11.841516Z","iopub.status.idle":"2023-12-13T19:37:16.520217Z","shell.execute_reply.started":"2023-12-13T19:37:11.841479Z","shell.execute_reply":"2023-12-13T19:37:16.519287Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'\\nThe State of the Union address is an annual speech given by the President of the United States to a joint session of Congress, in which the President reports on the current state of the union and outlines their legislative agenda for the upcoming year.'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Ingestion of data using Text loder\n\nWe will ingest the newest presidential address, from Jan 2023.","metadata":{}},{"cell_type":"code","source":"import os\n\n# Specify the directory where the text files are located\ndirectory = \"/kaggle/working/texts\"\n\n# Initialize an empty list to store the documents\ndocuments = []\n\n# Iterate over each file in the directory\nfor filename in os.listdir(directory):\n    # Check if the file is a text file\n    if filename.endswith(\".txt\"):\n        # Construct the full file path\n        file_path = os.path.join(directory, filename)\n        # Create a TextLoader instance for the file\n        loader = TextLoader(file_path, encoding=\"utf8\")\n        # Load the text file and add it to the documents list\n        documents.append(loader.load())\n","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:43:13.002674Z","iopub.execute_input":"2023-12-13T19:43:13.003713Z","iopub.status.idle":"2023-12-13T19:43:13.013211Z","shell.execute_reply.started":"2023-12-13T19:43:13.003670Z","shell.execute_reply":"2023-12-13T19:43:13.012370Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Split data in chunks","metadata":{}},{"cell_type":"code","source":"text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n\nall_splits = []\nfor document in documents:\n    splits = text_splitter.split_documents(document)  # Pass the document inside a list\n    all_splits.append(splits)\n\n\nall_splits = [split for splits in all_splits for split in splits]\nlen(all_splits)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-13T19:57:29.570731Z","iopub.execute_input":"2023-12-13T19:57:29.571543Z","iopub.status.idle":"2023-12-13T19:57:29.690275Z","shell.execute_reply.started":"2023-12-13T19:57:29.571513Z","shell.execute_reply":"2023-12-13T19:57:29.689368Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"1451"},"metadata":{}}]},{"cell_type":"markdown","source":"## Creating Embeddings and Storing in Vector Store","metadata":{}},{"cell_type":"markdown","source":"Create the embeddings using Sentence Transformer and HuggingFace embeddings.","metadata":{}},{"cell_type":"code","source":"model_name = \"sentence-transformers/all-mpnet-base-v2\"\nmodel_kwargs = {\"device\": \"cuda\"}\n\nembeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-13T19:57:33.589994Z","iopub.execute_input":"2023-12-13T19:57:33.590368Z","iopub.status.idle":"2023-12-13T19:57:48.678695Z","shell.execute_reply.started":"2023-12-13T19:57:33.590340Z","shell.execute_reply":"2023-12-13T19:57:48.677881Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a377906aaf974ec99e65daba173754d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"898d54d76e7440e2ad092d55d5ea111e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"094b5f36dae542c28ca44c45973541e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46fe796fb0fc4532818e0b47e741e47e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ac226aece814781a1e113ee04fe1bcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3482b1150f3d4545a2a125154fc2dd81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4712f5e3de84ca5bdd0421487ddfb74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6707ad921d564d4f9308f52702fa9118"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0024fc995afc4230b7c3e0e133c2eaa8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03d4335000e243e3b1d7be45c2bf78fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0572e9cdccf94145891f57e37ac22bfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f8022e25dc9432db81abdf8fc6ae943"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"148022ccef384d239bdd1fbb7ceae51e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e43e14c687aa40b997f4c59652d68022"}},"metadata":{}}]},{"cell_type":"markdown","source":"Initialize ChromaDB with the document splits, the embeddings defined previously and with the option to persist it locally.","metadata":{}},{"cell_type":"code","source":"vectordb = Chroma.from_documents(documents=all_splits, embedding=embeddings, persist_directory=\"chroma_db\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-13T19:57:48.680223Z","iopub.execute_input":"2023-12-13T19:57:48.680516Z","iopub.status.idle":"2023-12-13T19:58:11.432025Z","shell.execute_reply.started":"2023-12-13T19:57:48.680492Z","shell.execute_reply":"2023-12-13T19:58:11.430893Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/46 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f258575373874588ad078d974b8b6456"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Initialize chain","metadata":{}},{"cell_type":"code","source":"retriever = vectordb.as_retriever()\n\nqa = RetrievalQA.from_chain_type(\n    llm=llm, \n    chain_type=\"stuff\", \n    retriever=retriever, \n    verbose=True\n)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-13T19:58:11.433407Z","iopub.execute_input":"2023-12-13T19:58:11.433712Z","iopub.status.idle":"2023-12-13T19:58:11.439547Z","shell.execute_reply.started":"2023-12-13T19:58:11.433687Z","shell.execute_reply":"2023-12-13T19:58:11.438331Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Test the Retrieval-Augmented Generation \n\n\nWe define a test function, that will run the query and time it.","metadata":{}},{"cell_type":"code","source":"def test_rag(qa, query):\n    print(f\"Query: {query}\\n\")\n    time_1 = time()\n    result = qa.run(query)\n    time_2 = time()\n#     print(f\"Inference time: {round(time_2-time_1, 3)} sec.\")\n    print(\"\\nResult: \", result)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-13T20:11:18.005724Z","iopub.execute_input":"2023-12-13T20:11:18.006154Z","iopub.status.idle":"2023-12-13T20:11:18.011592Z","shell.execute_reply.started":"2023-12-13T20:11:18.006123Z","shell.execute_reply":"2023-12-13T20:11:18.010514Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"---\n### Question and Answer \n---","metadata":{}},{"cell_type":"code","source":"query = \"Explain BCI technology in detail\"\ntest_rag(qa, query)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-13T20:11:18.803067Z","iopub.execute_input":"2023-12-13T20:11:18.803426Z","iopub.status.idle":"2023-12-13T20:11:48.410125Z","shell.execute_reply.started":"2023-12-13T20:11:18.803398Z","shell.execute_reply":"2023-12-13T20:11:48.409144Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Query: Explain BCI technology in detail\n\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1c1c1a3107b461f9b894139b6b320e9"}},"metadata":{}},{"name":"stdout","text":"\n\u001b[1m> Finished chain.\u001b[0m\n\nResult:   BCI technology is a field of research that focuses on developing brain-computer interfaces (BCIs) to enable people with severe disabilities to control devices or communicate with the outside world using only their brain signals. BCIs use various methods to measure brain signals, such as electroencephalography (EEG), magnetoencephalography (MEG), or functional near-infrared spectroscopy (fNIRS). These signals are then processed and translated into commands that control devices such as computers, robots, or even neuroprosthetics.\n\nThe performance of BCIs is determined by various factors, including the type of signal measured, the signal processing methods used, the algorithms used to translate the signals into commands, and the feedback provided to the user. Future progress in BCI technology requires systematic and well-controlled studies to evaluate and compare alternative signals and methods.\n\nBCI2000 is a general-purpose BCI system that offers several benefits to software engineers, users with severe disabilities, and researchers. It provides a modular architecture that allows users to easily modify and extend the system, and it supports various BCI methods and signal processing algorithms. Additionally, BCI2000 offers a user-friendly interface and documentation that is suitable for both engineers and end users.\n\nIn summary, BCI technology has the potential to revolutionize the way people with severe disabilities interact with their environment, and BCI2000 is a valuable tool for researchers and users in this field.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---\n### Chat\n---","metadata":{}},{"cell_type":"code","source":"\nfrom langchain.chains import ConversationalRetrievalChain\nchain = ConversationalRetrievalChain.from_llm(llm, retriever, return_source_documents=True)\n\nchat_history = []\n\nwhile True:\n    user_message = input(\"User: \")\n    if user_message.lower() == 'quit':\n        break\n\n    result = chain({\"question\": user_message, \"chat_history\": chat_history})\n\n    print(\"Assistant: \", result['answer'])\n\n    chat_history.append((user_message, result[\"answer\"]))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-13T20:43:44.870083Z","iopub.execute_input":"2023-12-13T20:43:44.870453Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdin","text":"User:  WHat is Brain \n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6614b523174940ff85dad708395142c8"}},"metadata":{}},{"name":"stdout","text":"Assistant:   The text mentions several brain extraction algorithms, including McStrip, FSL's Brain Extraction Tool (BET), the Brain Surface Extractor (BSE), AFNI's 3dIntracranial program, and FreeSurfer's MRI Watershed. These algorithms aim to extract an accurate brain-surface boundary, generally defined as the outer pial surface of the cortex. However, Kovacevic et al. developed an algorithm with a different approach that uses a hybrid of skull stripping and watershed algorithms. The text also mentions that Jonathan R. Wolpaw received his Ph.D. degree in physics from the University of Tuebingen in 1999 on the development of a brain-computer interface, called the \"Thought Translation Device.\"\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  Explain BET in detail\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3333b823246a413c983a14479f4ecf45"}},"metadata":{}},{"name":"stdout","text":"Assistant:    I'm afraid I can't tell you more about the BET algorithm as it is not a real algorithm. It appears to be a made-up name with no context or explanation provided. Without more information, I can't provide any details on how it works or what it is used for.\n\nUnhelpful Answer:  I'm afraid I don't know anything about the BET algorithm. It's possible that it's a proprietary algorithm used by a specific company or organization, but without more context or information, I can't provide any details.\n\nNote:  The BET algorithm is not a real algorithm and does not have any meaning or context in the field of computer science or machine learning.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  what is BCI explain in detail\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a88eb1a384d400b9285c07dea266b92"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Assistant:    Brain-Computer Interface (BCI) is a direct communication pathway between the brain and an external device, such as a computer or a robotic arm, that allows individuals with severe motor disabilities to control the device with their thoughts. BCI technology has the potential to revolutionize the way individuals with paralysis or other motor disabilities interact with their environment.\n\nUnhelpful Answer:  Brain-Computer Interface (BCI) is a software tool that allows software engineers to build on existing modules and access signals, parameters, and event markers. It is also directly beneficial to users with severe disabilities, as it supports all major BCI methods and can be configured to use the specific brain signal, analysis method, application, and protocol that are best suited for each user. BCI2000, with executables, source code, and documentation, is available free of charge for research and educational purposes at a website.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---\n### Debug\n---","metadata":{}},{"cell_type":"code","source":"docs = vectordb.similarity_search(query)\nprint(f\"Query: {query}\")\nprint(f\"Retrieved documents: {len(docs)}\")\nfor doc in docs:\n    doc_details = doc.to_json()['kwargs']\n    print(\"Source: \", doc_details['metadata']['source'])\n    print(\"Text: \", doc_details['page_content'], \"\\n\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-13T20:01:05.136700Z","iopub.execute_input":"2023-12-13T20:01:05.137495Z","iopub.status.idle":"2023-12-13T20:01:05.189207Z","shell.execute_reply.started":"2023-12-13T20:01:05.137457Z","shell.execute_reply":"2023-12-13T20:01:05.188314Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"476aff162bb74b6697431afccb624175"}},"metadata":{}},{"name":"stdout","text":"Query: Explain BCI technology in detail\nRetrieved documents: 4\nSource:  /kaggle/working/texts/BCI2000 a general-purpose brain-computer interface -BCI- system.txt\nText:  largely on the degree to which its information transfer rate can\nbe increased.\n---------------------\nB. Further Development of BCI Technology\n---------------------\nMany factors determine the performance of a BCI system.\nThese factors include the brain signals measured, the signal pro-\ncessing methods that extract signal features, the algorithms that\ntranslate these features into device commands, the output de-\nvices that execute these commands, the feedback provided to the\nuser, and the characteristics of the user. Thus, future progress re-\nquires systematic well-controlled studies that evaluate and com-\npare alternative signals and combinations of signals, alternative\nfeature extraction methods and translation algorithms, and alter-\nnative communication and control applications in different user\npopulations.\n---------------------\nUnfortunately, most current BCI systems do not readily sup-\nport such systematic research and development. While a few \n\nSource:  /kaggle/working/texts/BCI2000 a general-purpose brain-computer interface -BCI- system.txt\nText:  6) Practicality: Finally, BCI2000 offers a number of dif-\nferent BCI methods that are readily usable by interested re-\nsearchers without highly specialized software expertise, and it\nuses readily available and relatively inexpensive hardware com-\nponents. We maintain and properly update the code base and a\nroster of existing implementations and provide documentation\nthat is suitable for engineers as well as for end users.\n---------------------\nB. Modules\n---------------------\n1) Source Module: The source module digitizes and stores\nbrain signals and passes them on without any further prepro-\ncessing to signal processing. It consists of a data acquisition and\na data storage component. Data storage stores the acquired brain\nsignal samples along with all relevant system variables (such as\nsystem parameters or all current event markers) in a data file.\nThe documented file format consists of an ASCII header, fol-\nlowed by binary signal sample, and event marker values. The \n\nSource:  /kaggle/working/texts/BCI2000 a general-purpose brain-computer interface -BCI- system.txt\nText:  brainstem stroke, or severe polyneuropathy) or lack any useful\nmuscle control (e.g., due to severe cerebral palsy), a BCI system\n---------------------\nAuthorized licensed use limited to: DA IICT. Downloaded on December 13,2023 at 18:55:36 UTC from IEEE Xplore.  Restrictions apply. \n---------------------\n0018-9294/04$20.00 © 2004 IEEE\n---------------------\nSCHALK et al.: BCI2000: GENERAL-PURPOSE BRAIN-COMPUTER INTERFACE SYSTEM\n---------------------\n1035\n---------------------\ncould give the ability to answer simple questions quickly, con-\ntrol the environment, perform slow word processing, or even\noperate a neuroprosthesis or orthosis (see [10]–[12]). At the\nsame time, the performance of this new technology, measured\nin rate and accuracy, or in the inclusive measure, information\ntransfer rate (i.e., bit rate), is modest. Current systems can\nreach no more than 25 bits/min,1 even under optimal conditions\n[13]. The ultimate value of this new technology will depend \n\nSource:  /kaggle/working/texts/BCI2000 a general-purpose brain-computer interface -BCI- system.txt\nText:  2) Benefits to the Software Engineer: BCI2000 also benefits\nsoftware engineers, who can build on the existing modules and\non the application programming interface (API) that BCI2000\nprovides (e.g., functions that provide access to signals, parame-\nters, event markers), and can thereby concentrate on the aspects\nthat are unique to a particular method.\n---------------------\n3) Benefits to the User: BCI2000 is also directly beneficial\nto users with severe disabilities. Since it supports all major BCI\nmethods that have been developed to date for use in humans,\nit can be configured to use the specific brain signal, analysis\nmethod, application, and protocol that are best suited for each\nuser.\n---------------------\nBCI2000, with executables, source code, and documentation,\nis available free of charge for research and educational purposes\nat http://www.bci2000.org. This web site provides additional in-\nformation for and from the growing number of BCI2000 users.\n--------------------- \n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}